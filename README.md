# Language_Translator
This project demonstrates how to use seq2seq architecture with attention mechanism to build a neural machine translation system in Python. The project shows how to preprocess and vectorize input data using tokenization and one-hot encoding techniques.
